# AI 学习记录模板（适配你的学习方式）

> 这个模板是为你的学习思维结构设计的：从公理到推演，从历史到当下，从机制到应用。只需要把内容添进去即可。

---

## 0. 本次学习的核心主题（Topic）

* *一句话描述你正在理解的核心概念/问题是什么。*
线性代数（Linear Algebra）、**凸优化（Convex Optimization）和统计学（Statistics）**的第一性原理出发;
概念拆解为三个核心模块：
度量工具：范数（Norms）——我们如何定义“大小”？
约束手段：正则化（Regularization）——我们为何以及如何限制模型？
描述工具：矩（Moments）——我们如何描述数据的形状？

---

* Batch Norm:由于BN使用的是当前Batch的统计量，它总能把数据强行拉回正态分布。
对于一个Batch中的输入数据 $x$，BN的变换如下：
  - $$\hat{x} = \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}}$$$$y = \gamma \hat{x} + \beta$$
  - 符号解释：$x$: 输入特征向量。
  - $\mu$: 均值（Mean），描述数据的中心位置。
  - $\sigma^2$: 方差（Variance），描述数据的离散程度。
  - $\epsilon$: 极小值（Epsilon），防止分母为0。
  - $\gamma, \beta$: 可学习参数（Learnable Parameters），用于恢复网络的表达能力，防止归一化破坏了特征的分布。
  
* Batch Norm中的分布偏移（Distribution Shift）噩梦:
源于训练时的随机近似（Stochastic Approximation）与推理时的确定性期望（Deterministic Expectation）之间的数学不一致性。
噩梦的根源在于 $\mu$ 和 $\sigma$ (统计量)的来源不同：
训练 (Training):当前Batch的统计量 ($\mu_B, \sigma_B$)局部估计（Local Estimation）。模型实际上学会了利用“当前这批数据”的特性来归一化自己。
推理 (Inference):全局移动平均 ($\mu_{running}, \sigma_{running}$)全局期望（Global Expectation）。通常使用训练过程中所有Batch统计量的滑动平均值。
表现形式:训练时的 $\mu_B$ 和 推理时的 $\mu_{running}$ 出现巨大的鸿沟。
  - 独立同分布（I.I.D.）假设的破裂
    - BN强烈依赖于一个假设：每一个Mini-batch都是总体数据集的无偏采样。如果这个假设不成立，$\mu_{running}$ 就无法代表真实的测试数据。
  - 实例归一化与群体归一化的混淆
    - 在训练时，因为使用的是Batch统计量，BN不仅归一化了特征，实际上还引入了样本间的相互依赖。即：样本 A 的输出结果，取决于同在一个Batch里的样本 B、C、D 是什么（因为它们共同决定了 $\mu_B$）。而在推理时，这种依赖消失了。
  - 训练集与测试集的域偏移 (Domain Shift),这是最直观的分布偏移。
    - 如果训练集是ImageNet（自然图像），测试集是素描画。训练集的 $\mu_{running}$ 是自然图像的统计特征。测试数据进来时，被强行减去了自然图像的均值。
    - 结果：特征空间发生扭曲，神经网络后续的权重矩阵处理的是错误的数值范围。
* 解决方案的演进（理解原理）
为了解决这个噩梦，后续的研究试图切断对“Batch统计量”的依赖，转向**样本内（Instance-level）**的统计。

Layer Normalization (LN) / Group Normalization (GN)：

原理：不再跨样本（Batch维度）计算均值方差，而是在单个样本内部（Channel维度）计算。

解决：彻底消除了训练和推理的不一致性。无论Batch size是多少，无论分布怎么变，对单个样本的处理逻辑是恒定的。
---

## 1. 公理 / 定义区（Axioms & Definitions）

* 数学或概念公理：
* 范数 (Norms) :向量空间的“尺子”:选用不同的范数 (norm) —— 比如 L₁, L₂, L∞ ……其实是在定义不同的“世界
  > 在数学上，范数是将向量映射到非负实数的函数，本质是定义在这个空间中的“长度”或“大小”的单位。设向量 $\mathbf{x} = [x_1, x_2, ..., x_n]$。
  > p-范数 (Lp norm) 随着 𝑝 从 1 → 2 → … → ∞ 变化。
    - p=1：L₁-范数 → 单位球是菱形 (diamond),xn绝对值相加
    - p=2：L₂-范数 → 单位球是圆 (circle),xn平方和开根
    - p→∞：L∞-范数 → 单位球渐趋正方形 (square),max(∣x∣,∣y∣)≤1
* 正则化(regularization):约束优化的本质
  > 为什么要加正则化？
  -  第一性原理：为了解决病态问题（Ill-posed Problem）和过拟合（Overfitting）。
  -  在损失函数 $J(\mathbf{w})$ 后面加上一项 $\lambda \|\mathbf{w}\|$，本质是在**带约束的优化问题（Constrained Optimization）**中引入拉格朗日乘子（Lagrange Multiplier）。
  - 
*   
---

## 2. 这个概念被发明的历史背景（Historical Motivation）

> 为什么会有这个方法、模型、损失函数、架构？
> 当年它是为了解决什么问题？

* 背景：
* 谁提出的：
* 早期版本长什么样：
* 解决了什么痛点：

---

## 3. 第一性原理拆解（First Principles Breakdown）

> 用最基本的物理直觉、数学构件、逻辑公理拆解它。

* 基本假设：
* 不依赖“它像什么”，而是解释“它是什么”：
* 数学结构：向量空间 / 优化目标 / 变换结构 / 概率模型 等

---

## 4. 数学与公式推导（Math & Derivation）

> 记录本质的数学，而不是单纯把公式当成答案。

* 损失函数推导：
* 梯度更新推导：
* 参数化结构：
* 关键等式（手写推导过程）：

---

## 5. 机制层面（Mechanism Level）

> 这个东西运行时，内部到底发生了什么？
> 像显微镜一样拆解成过程。

* 输入流动：
* 中间表示（embedding / feature map）：
* 梯度流：
* 收敛逻辑：

---

## 6. 与其他方法的边界与区别（Boundary Check）

> 为了避免混淆，把它与“相似但不同”的东西划清楚。

* 它不是：
* 为什么它不是：
* 它的边界在哪里：

---

## 7. 实际应用（Practical Usage）

> 在真实工程中如何使用它？

* 典型适用场景：
* 常见超参：
* 工程注意点：

---

## 8. 与 MIL / CV / 深度学习体系的连接点（Integration）

> 把它放回更大的知识体系里。

* 在 MIL 中属于哪一环：
* 在 CV pipeline 的位置：
* 和优化/梯度/表示学习的联系：

---

## 9. 潜在的陷阱与误区（Pitfalls）

> 记录那些容易误会、容易踩坑的地方，让未来的你少走弯路。

* 数学误解：
* 假想边界：
* 工程坑点：

---

## 10. 核心图示（Diagram）

> 用一句话说明要画什么图，之后自己画或让 AI 给你生成。

* 机制图：
* 梯度流图：
* 数学结构图：

---

## 11. 停放区（Parking Lot）

> 当你追溯到更底层公理导致“概念基础塌陷”时，把这些问题放这里。

* 待澄清：
* 纯哲学性问题：
* 暂时对实际训练无影响的问题：

---

## 12. 当下理解总结（Current Understanding Summary）

> 简短总结你现在的理解版本，未来版本可以覆盖它。

* 当前版本：
* 懂到什么程度了：
* 下一步要补什么：
